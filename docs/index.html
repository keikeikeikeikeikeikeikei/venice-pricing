<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Venice Model Pricing Dashboard</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;500;600;700&family=Inter:wght@400;500;600&display=swap');

        :root {
            /* Light Mode - Crisp & Airy */
            --bg-body: #f3f4f6;
            --text-main: #1f2937;
            --text-muted: #6b7280;
            --card-bg: #ffffff;
            --border-color: #e5e7eb;
            --primary: #6366f1;
            /* Indigo */
            --primary-gradient: linear-gradient(135deg, #6366f1 0%, #a855f7 100%);
            --secondary: #ec4899;
            --success: #10b981;
            --bar-bg: #e5e7eb;
            --header-bg: rgba(255, 255, 255, 0.8);
            --header-blur: 12px;
            --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
            --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            --radius-md: 12px;
            --radius-lg: 16px;
        }

        @media (prefers-color-scheme: dark) {
            :root {
                /* Dark Mode - Deep & Premium */
                --bg-body: #0f172a;
                /* Slate 900 */
                --text-main: #f3f4f6;
                --text-muted: #94a3b8;
                --card-bg: #1e293b;
                /* Slate 800 */
                --border-color: #334155;
                --primary: #818cf8;
                --primary-gradient: linear-gradient(135deg, #818cf8 0%, #c084fc 100%);
                --secondary: #f472b6;
                --success: #34d399;
                --bar-bg: #334155;
                --header-bg: rgba(30, 41, 59, 0.8);
                --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.3);
                --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.5);
            }
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', system-ui, sans-serif;
            background-color: var(--bg-body);
            color: var(--text-main);
            margin: 0;
            padding: 40px 20px;
            line-height: 1.6;
            transition: background-color 0.3s ease, color 0.3s ease;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        /* Header */
        header {
            margin-bottom: 40px;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        h1 {
            font-family: 'Outfit', sans-serif;
            font-weight: 700;
            font-size: 2.5rem;
            margin: 0;
            background: var(--primary-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            letter-spacing: -0.02em;
        }

        .meta {
            font-size: 0.95rem;
            color: var(--text-muted);
            font-weight: 500;
        }

        /* Controls Area */
        .controls {
            background: var(--card-bg);
            padding: 20px;
            border-radius: var(--radius-lg);
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-sm);
            margin-bottom: 30px;
            display: flex;
            flex-direction: column;
            gap: 20px;
            transition: box-shadow 0.3s ease;
        }

        .controls:hover {
            box-shadow: var(--shadow-md);
        }

        .main-controls {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            align-items: center;
            justify-content: space-between;
        }

        /* Tabs */
        .tabs {
            display: flex;
            background: var(--bg-body);
            padding: 4px;
            border-radius: 10px;
            gap: 4px;
        }

        .tab-btn {
            padding: 8px 24px;
            border: none;
            background: transparent;
            color: var(--text-muted);
            cursor: pointer;
            border-radius: 8px;
            font-weight: 600;
            font-family: 'Outfit', sans-serif;
            font-size: 0.95rem;
            transition: all 0.2s ease;
        }

        .tab-btn:hover {
            color: var(--text-main);
        }

        .tab-btn.active {
            background: var(--card-bg);
            color: var(--primary);
            box-shadow: var(--shadow-sm);
        }

        /* Filter Bar */
        .filter-bar {
            display: flex;
            gap: 12px;
            flex-wrap: wrap;
            padding-top: 5px;
        }

        .filter-item {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 0.9em;
            cursor: pointer;
            user-select: none;
            padding: 8px 16px;
            background: var(--bg-body);
            color: var(--text-main);
            border-radius: 30px;
            /* Pill shape */
            border: 1px solid transparent;
            transition: all 0.2s ease;
            font-weight: 500;
        }

        .filter-item:hover {
            background: var(--border-color);
        }

        .filter-item input:checked+span {
            color: var(--primary);
            font-weight: 600;
        }

        /* Search Box */
        .search-box {
            flex-grow: 1;
            max-width: 400px;
            position: relative;
        }

        .search-box input {
            padding: 10px 16px;
            padding-left: 40px;
            /* Space for icon */
            border: 1px solid var(--border-color);
            border-radius: var(--radius-md);
            background: var(--bg-body);
            color: var(--text-main);
            width: 100%;
            font-family: inherit;
            font-size: 0.95rem;
            transition: border-color 0.2s, box-shadow 0.2s;
        }

        .search-box input:focus {
            outline: none;
            border-color: var(--primary);
            box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
        }

        /* Add search icon via CSS pseudo-element for simplicity without SVG clutter */
        .search-box::before {
            content: "üîç";
            position: absolute;
            left: 12px;
            top: 50%;
            transform: translateY(-50%);
            font-size: 1rem;
            opacity: 0.5;
            pointer-events: none;
        }

        /* Table */
        .table-container {
            overflow-x: auto;
            background: var(--card-bg);
            border-radius: var(--radius-lg);
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-md);
        }

        table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.95rem;
            min-width: 1000px;
        }

        th,
        td {
            padding: 16px 24px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }

        th {
            background: var(--header-bg);
            backdrop-filter: blur(var(--header-blur));
            -webkit-backdrop-filter: blur(var(--header-blur));
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.75rem;
            letter-spacing: 0.05em;
            color: var(--text-muted);
            position: sticky;
            top: 0;
            z-index: 10;
            cursor: pointer;
            transition: color 0.2s;
        }

        th:hover {
            color: var(--primary);
        }

        tbody tr {
            transition: background-color 0.15s ease;
        }

        tbody tr:hover {
            background-color: rgba(99, 102, 241, 0.03);
            /* Very subtle primary tint */
        }

        tbody tr:last-child td {
            border-bottom: none;
        }

        /* Column Specifics */
        .model-name {
            font-family: 'Outfit', sans-serif;
            font-weight: 600;
            font-size: 1.05rem;
            color: var(--text-main);
            text-decoration: none;
            margin-bottom: 4px;
            display: inline-block;
        }

        .model-name:hover {
            color: var(--primary);
            text-decoration: none;
        }

        .model-id {
            font-family: 'ui-monospace', 'SFMono-Regular', 'Menlo', monospace;
            font-size: 0.75em;
            color: var(--text-muted);
            margin-bottom: 8px;
            opacity: 0.8;
        }

        /* Tags */
        .tag-row {
            display: flex;
            gap: 6px;
            flex-wrap: wrap;
        }

        .cap-badge {
            display: inline-flex;
            align-items: center;
            padding: 2px 8px;
            border-radius: 6px;
            background: var(--bg-body);
            border: 1px solid var(--border-color);
            font-size: 0.7em;
            font-weight: 600;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.03em;
        }

        /* Price Bars */
        .price-cell {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        .price-val {
            font-weight: 600;
            font-feature-settings: "tnum";
            font-variant-numeric: tabular-nums;
        }

        .rel-bar-container {
            display: flex;
            align-items: center;
            gap: 10px;
            font-size: 0.75em;
            color: var(--text-muted);
        }

        /* Progress Bar */
        .rel-bar-container {
            width: 100%;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .rel-bar-bg {
            flex: 1;
            height: 6px;
            background: var(--bar-bg);
            border-radius: 3px;
            overflow: hidden;
        }

        .rel-bar-fill {
            height: 100%;
            width: 0%;
            border-radius: 3px;
            transition: width 0.5s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .bar-low {
            background: var(--success);
        }

        .bar-med {
            background: #f59e0b;
        }

        .bar-high {
            background: #ef4444;
        }

        /* Price Bridge */
        .price-bridge {
            display: flex;
            flex-direction: column;
            gap: 6px;
            min-width: 200px;
            padding: 4px 0;
        }

        .price-bridge-top {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.85rem;
        }

        .price-value-group {
            display: flex;
            flex-direction: column;
            line-height: 1.2;
        }

        .price-value-label {
            font-size: 0.65rem;
            color: var(--text-muted);
            text-transform: uppercase;
            font-weight: 700;
        }

        .price-value-num {
            font-weight: 600;
            font-family: inherit;
        }

        .price-bridge-avg-info {
            text-align: center;
            flex: 1;
            font-weight: 800;
            color: var(--primary);
            font-size: 0.95rem;
        }

        th.col-combined-price {
            min-width: 220px;
        }

        .price-header-sort {
            font-size: 0.65rem;
            color: var(--text-muted);
            margin-top: 4px;
            display: flex;
            gap: 4px;
            justify-content: center;
        }

        .price-header-sort span {
            cursor: pointer;
            padding: 0 4px;
        }

        .price-header-sort span.active-sort {
            color: var(--primary);
            font-weight: 800;
            text-decoration: underline;
        }

        /* Feature Badges */
        .feature-tags {
            display: flex;
            gap: 6px;
            flex-wrap: wrap;
        }

        .feature-badge {
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.02em;
            border: 1px solid transparent;
        }

        /* Feature Colors */
        .feat-reasoning {
            background: rgba(139, 92, 246, 0.1);
            color: #8b5cf6;
            border-color: rgba(139, 92, 246, 0.2);
        }

        .feat-vision {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            border-color: rgba(16, 185, 129, 0.2);
        }

        .feat-func {
            background: rgba(245, 158, 11, 0.1);
            color: #f59e0b;
            border-color: rgba(245, 158, 11, 0.2);
        }

        .feat-code {
            background: rgba(59, 130, 246, 0.1);
            color: #3b82f6;
            border-color: rgba(59, 130, 246, 0.2);
        }

        .feat-search {
            background: rgba(236, 72, 153, 0.1);
            color: #ec4899;
            border-color: rgba(236, 72, 153, 0.2);
        }

        .feat-logprobs {
            background: rgba(107, 114, 128, 0.1);
            color: var(--text-muted);
            border-color: rgba(107, 114, 128, 0.2);
        }

        .feat-json {
            background: rgba(79, 70, 229, 0.1);
            color: #4f46e5;
            border-color: rgba(79, 70, 229, 0.2);
        }

        .feat-cache {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            border-color: rgba(16, 185, 129, 0.2);
        }

        /* Links */
        a {
            color: var(--primary);
            transition: color 0.2s;
        }

        a:hover {
            color: var(--secondary);
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        tbody tr {
            animation: fadeIn 0.3s ease-out forwards;
        }
    </style>
</head>

<body>

    <div class="container">
        <header>
            <h1>Venice Model Pricing</h1>
            <div class="meta">Generated from Live API Data (2025-12-28 00:00)</div>
        </header>

        <div class="controls">
            <div class="main-controls">
                <div class="tabs">
                    <button class="tab-btn active" onclick="switchTab('text')">Text</button>
                    <button class="tab-btn" onclick="switchTab('image')">Image</button>
                    <button class="tab-btn" onclick="switchTab('video')">Video</button>
                </div>

                <div class="search-box">
                    <input type="text" id="searchInput" placeholder="Search (Refine by Name, ID, Source)..."
                        oninput="renderTable()">
                </div>
            </div>

            <div id="filterBar" class="filter-bar">
                <!-- Filters injected via JS -->
            </div>
        </div>

        <div class="table-container">
            <table>
                <thead id="tableHead">
                    <!-- Headers injected via JS -->
                </thead>
                <tbody id="tableBody">
                    <!-- Rows injected via JS -->
                </tbody>
            </table>
        </div>
    </div>

    <!-- Data Injection -->
    <script>
        window.veniceModels = {
  "text": [
    {
      "created": 1742262554,
      "id": "venice-uncensored",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.2,
            "diem": 0.2
          },
          "output": {
            "usd": 0.9,
            "diem": 0.9
          }
        },
        "availableContextTokens": 32768,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp16",
          "supportsAudioInput": false,
          "supportsFunctionCalling": false,
          "supportsLogProbs": true,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "Designed for maximum creative freedom and authentic interaction. Ideal for open-ended exploration, roleplay, and unfiltered dialogue. Features minimal content restrictions.",
        "name": "Venice Uncensored 1.1",
        "modelSource": "https://huggingface.co/cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
        "offline": false,
        "privacy": "private",
        "traits": [
          "most_uncensored"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1711929600,
      "id": "zai-org-glm-4.6",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.85,
            "diem": 0.85
          },
          "output": {
            "usd": 2.75,
            "diem": 2.75
          }
        },
        "availableContextTokens": 202752,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "GLM-4.6 is a large language model developed by Zhiyuan AI, featuring strong reasoning capabilities and support for multiple languages. Supports the largest context window for processing extensive text and detailed analysis.",
        "name": "GLM 4.6",
        "modelSource": "https://huggingface.co/zai-org/GLM-4.6",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-4b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.05,
            "diem": 0.05
          },
          "output": {
            "usd": 0.15,
            "diem": 0.15
          }
        },
        "availableContextTokens": 32768,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.6
          },
          "top_p": {
            "default": 0.95
          }
        },
        "description": "Optimized for speed and efficiency. Best for quick answers, simple queries, and lightweight tasks on mobile or low-latency connections.",
        "name": "Venice Small",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-4B",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1742262554,
      "id": "mistral-31-24b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.5,
            "diem": 0.5
          },
          "output": {
            "usd": 2,
            "diem": 2
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.15
          },
          "top_p": {
            "default": 1
          }
        },
        "description": "Balanced blend of speed and capability. Handles most everyday tasks with reliability, and supports image analysis. Ideal for general use with moderate complexity.",
        "name": "Venice Medium",
        "modelSource": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default_vision"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-235b-a22b-thinking-2507",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.45,
            "diem": 0.45
          },
          "output": {
            "usd": 3.5,
            "diem": 3.5
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.6
          },
          "top_p": {
            "default": 0.95
          }
        },
        "description": "Built for in-depth research and handling long, complex documents. Ideal for technical work, multimodal input, and high-precision tasks.",
        "name": "Qwen 3 235B A22B Thinking 2507",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-235b-a22b-instruct-2507",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.15,
            "diem": 0.15
          },
          "output": {
            "usd": 0.75,
            "diem": 0.75
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.8
          }
        },
        "description": "Built for in-depth research and handling long, complex documents. Ideal for technical work, multimodal input, and high-precision tasks.",
        "name": "Qwen 3 235B A22B Instruct 2507",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-next-80b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.35,
            "diem": 0.35
          },
          "output": {
            "usd": 1.9,
            "diem": 1.9
          }
        },
        "availableContextTokens": 262144,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp16",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.8
          }
        },
        "description": "Optimized for speed and efficiency.",
        "name": "Qwen 3 Next 80b",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "qwen3-coder-480b-a35b-instruct",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.75,
            "diem": 0.75
          },
          "output": {
            "usd": 3,
            "diem": 3
          }
        },
        "availableContextTokens": 262144,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.8
          }
        },
        "description": "Optimized for code.",
        "name": "Qwen 3 Coder 480b",
        "modelSource": "https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default_code"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1711929600,
      "id": "hermes-3-llama-3.1-405b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 1.1,
            "diem": 1.1
          },
          "output": {
            "usd": 3,
            "diem": 3
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": false,
          "supportsLogProbs": false,
          "supportsReasoning": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "Hermes 3 405B is a frontier level, full parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.",
        "name": "Hermes 3 Llama 3.1 405b",
        "modelSource": "https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-405B",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1711929600,
      "id": "google-gemma-3-27b-it",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.12,
            "diem": 0.12
          },
          "output": {
            "usd": 0.2,
            "diem": 0.2
          }
        },
        "availableContextTokens": 202752,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to Gemma 2.",
        "name": "Google Gemma 3 27B Instruct",
        "modelSource": "https://huggingface.co/google/gemma-3-27b-it",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1745903059,
      "id": "grok-41-fast",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.5,
            "diem": 0.5
          },
          "cache_input": {
            "usd": 0.125,
            "diem": 0.125
          },
          "output": {
            "usd": 1.25,
            "diem": 1.25
          }
        },
        "availableContextTokens": 262144,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.8
          }
        },
        "description": "Grok 4.1 Fast is xAI's best agentic tool-calling model that shines in real-world use cases like customer support and image analysis.",
        "name": "Grok 4.1 Fast",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1717795200,
      "id": "gemini-3-pro-preview",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 2.5,
            "diem": 2.5
          },
          "cache_input": {
            "usd": 0.625,
            "diem": 0.625
          },
          "output": {
            "usd": 15,
            "diem": 15
          }
        },
        "availableContextTokens": 202752,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": true,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": true,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.8
          }
        },
        "description": "Gemini 3 Pro is Google flagship frontier model for high-precision multimodal reasoning with strong performance across text, image, and code.",
        "name": "Gemini 3 Pro Preview",
        "modelSource": "https://deepmind.google/models/gemini/pro/",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1733369471,
      "id": "claude-opus-45",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 6,
            "diem": 6
          },
          "cache_input": {
            "usd": 0.6,
            "diem": 0.6
          },
          "output": {
            "usd": 30,
            "diem": 30
          }
        },
        "availableContextTokens": 202752,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": true,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "Claude Opus 4.5 is Anthropic's frontier reasoning model optimized for complex software engineering, agentic workflows, and long-horizon computer use. It offers strong multimodal capabilities, competitive performance across real-world coding and reasoning benchmarks, and improved robustness to prompt injection.",
        "name": "Claude Opus 4.5",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1711929600,
      "id": "openai-gpt-oss-120b",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.07,
            "diem": 0.07
          },
          "output": {
            "usd": 0.3,
            "diem": 0.3
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsReasoning": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE) language model from OpenAI designed for high-reasoning, agentic, and general-purpose production use cases. The model supports configurable reasoning depth, full chain-of-thought access, and native tool use, including function calling, browsing, and structured output generation",
        "name": "OpenAI GPT OSS 120B",
        "modelSource": "https://huggingface.co/openai/gpt-oss-120b",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1717795200,
      "id": "kimi-k2-thinking",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.75,
            "diem": 0.75
          },
          "cache_input": {
            "usd": 0.1875,
            "diem": 0.1875
          },
          "output": {
            "usd": 3.2,
            "diem": 3.2
          }
        },
        "availableContextTokens": 262144,
        "capabilities": {
          "optimizedForCode": true,
          "quantization": "int4",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.8
          }
        },
        "description": "Kimi K2 Thinking is Moonshot AIs most advanced open reasoning model to date, extending the K2 series into agentic, long-horizon reasoning. Built on the trillion-parameter Mixture-of-Experts (MoE) architecture introduced in Kimi K2, it activates 32 billion parameters per forward pass and supports 256 k-token context windows.",
        "name": "Kimi K2 Thinking",
        "modelSource": "https://huggingface.co/moonshotai/Kimi-K2-Thinking",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1765065600,
      "id": "deepseek-v3.2",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 0.4,
            "diem": 0.4
          },
          "cache_input": {
            "usd": 0.2,
            "diem": 0.2
          },
          "output": {
            "usd": 1,
            "diem": 1
          }
        },
        "availableContextTokens": 163840,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": false,
          "supportsLogProbs": false,
          "supportsReasoning": true,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 1
          },
          "top_p": {
            "default": 0.95
          }
        },
        "description": "DeepSeek-V3.2 is an efficient large language model with DeepSeek Sparse Attention (DSA) for long contexts. It features strong reasoning and tool-use skills, achieving top results on the 2025 IMO and IOI.",
        "name": "DeepSeek V3.2",
        "modelSource": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1727966436,
      "id": "llama-3.2-3b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.15,
            "diem": 0.15
          },
          "output": {
            "usd": 0.6,
            "diem": 0.6
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp16",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": false,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.6
          },
          "top_p": {
            "default": 0.95
          }
        },
        "name": "Llama 3.2 3B",
        "modelSource": "https://huggingface.co/meta-llama/Llama-3.2-3B",
        "offline": false,
        "privacy": "private",
        "traits": [
          "fastest"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1733768349,
      "id": "llama-3.3-70b",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.7,
            "diem": 0.7
          },
          "output": {
            "usd": 2.8,
            "diem": 2.8
          }
        },
        "availableContextTokens": 131072,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "fp8",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": false,
          "supportsReasoning": false,
          "supportsResponseSchema": false,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.6
          },
          "top_p": {
            "default": 0.95
          }
        },
        "name": "Llama 3.3 70B",
        "modelSource": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
        "offline": false,
        "privacy": "private",
        "traits": [
          "function_calling_default",
          "default"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    },
    {
      "created": 1733960791,
      "id": "openai-gpt-52",
      "model_spec": {
        "betaModel": true,
        "pricing": {
          "input": {
            "usd": 2.19,
            "diem": 2.19
          },
          "cache_input": {
            "usd": 0.219,
            "diem": 0.219
          },
          "output": {
            "usd": 17.5,
            "diem": 17.5
          }
        },
        "availableContextTokens": 262144,
        "capabilities": {
          "optimizedForCode": false,
          "quantization": "not-available",
          "supportsAudioInput": false,
          "supportsFunctionCalling": true,
          "supportsLogProbs": true,
          "supportsReasoning": true,
          "supportsResponseSchema": true,
          "supportsVideoInput": false,
          "supportsVision": false,
          "supportsWebSearch": true
        },
        "constraints": {
          "temperature": {
            "default": 0.7
          },
          "top_p": {
            "default": 0.9
          }
        },
        "description": "GPT-5.2 is the latest frontier-grade model in the GPT-5 series, offering stronger agentic and long context performance compared to GPT-5.1. It uses adaptive reasoning to allocate computation dynamically, responding quickly to simple queries while spending more depth on complex tasks.",
        "name": "GPT-5.2",
        "modelSource": "",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "text"
    }
  ],
  "image": [
    {
      "created": 1743099022,
      "id": "venice-sd35",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 25,
            "max": 30
          },
          "widthHeightDivisor": 16
        },
        "supportsWebSearch": false,
        "name": "Venice SD35",
        "modelSource": "https://huggingface.co/stabilityai/stable-diffusion-3.5-large",
        "offline": false,
        "privacy": "private",
        "traits": [
          "default",
          "eliza-default"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1747080729,
      "id": "hidream",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "HiDream",
        "modelSource": "https://huggingface.co/HiDream-ai/HiDream-I1-Dev",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1764086377,
      "id": "flux-2-pro",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.04,
            "diem": 0.04
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 3000,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "Flux 2 Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1763653951,
      "id": "nano-banana-pro",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.18,
            "diem": 0.18
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 32768,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": true,
        "name": "Nano Banana Pro",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1762383600,
      "id": "seedream-v4",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.05,
            "diem": 0.05
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 1
        },
        "supportsWebSearch": false,
        "name": "SeedreamV4.5",
        "offline": false,
        "privacy": "anonymized",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1738704152,
      "id": "lustify-sdxl",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Lustify SDXL",
        "modelSource": "https://civitai.com/models/573152/lustify-sdxl-nsfw-checkpoint",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1736635129,
      "id": "lustify-v7",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 20,
            "max": 50
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Lustify v7",
        "modelSource": "https://civitai.com/models/573152/lustify-sdxl-nsfw-checkpoint",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1736635129,
      "id": "qwen-image",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 8,
            "max": 8
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Qwen Image",
        "modelSource": "https://huggingface.co/Qwen/Qwen-Image",
        "offline": false,
        "privacy": "private",
        "traits": [
          "highest_quality"
        ]
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1736635129,
      "id": "wai-Illustrious",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 1500,
          "steps": {
            "default": 25,
            "max": 30
          },
          "widthHeightDivisor": 16
        },
        "supportsWebSearch": false,
        "name": "Anime (WAI)",
        "modelSource": "https://civitai.com/models/827184?modelVersionId=1761560",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    },
    {
      "created": 1764758779,
      "id": "z-image-turbo",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "constraints": {
          "promptCharacterLimit": 7500,
          "steps": {
            "default": 8,
            "max": 8
          },
          "widthHeightDivisor": 8
        },
        "supportsWebSearch": false,
        "name": "Z-Image Turbo",
        "modelSource": "https://huggingface.co/Tongyi-MAI/Z-Image-Turbo",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "image"
    }
  ],
  "video": [
    {
      "created": 1765843200,
      "id": "wan-2.6-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "1080p",
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Wan 2.6",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.55
      }
    },
    {
      "created": 1765843200,
      "id": "wan-2.6-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4"
          ],
          "resolutions": [
            "1080p",
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Wan 2.6",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.55
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.5-preview-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "1080p",
            "720p",
            "480p"
          ],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Wan 2.5 Preview",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.28
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.5-preview-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "1080p",
            "720p",
            "480p"
          ],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Wan 2.5 Preview",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.28
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.2-a14b-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p",
            "580p",
            "480p"
          ],
          "durations": [
            "5s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Wan 2.2 A14B",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.06
      }
    },
    {
      "created": 1758825748,
      "id": "wan-2.1-pro-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [],
          "durations": [
            "6s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Wan 2.1 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.88
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-fast-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s",
            "12s",
            "14s",
            "16s",
            "18s",
            "20s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "LTX Video 2.0 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.06
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-fast-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s",
            "12s",
            "14s",
            "16s",
            "18s",
            "20s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "LTX Video 2.0 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.06
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-full-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "LTX Video 2.0 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.58
      }
    },
    {
      "created": 1732684002,
      "id": "ltx-2-full-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "durations": [
            "6s",
            "8s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "LTX Video 2.0 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.58
      }
    },
    {
      "created": 1758825748,
      "id": "ovi-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "5s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Ovi",
        "modelSource": "https://huggingface.co/chetwinlow1/Ovi",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.22
      }
    },
    {
      "created": 1733186476,
      "id": "kling-2.6-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "Kling 2.6 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.77
      }
    },
    {
      "created": 1733186476,
      "id": "kling-2.6-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "Kling 2.6 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.77
      }
    },
    {
      "created": 1758825748,
      "id": "kling-2.5-turbo-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Kling 2.5 Turbo Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.39
      }
    },
    {
      "created": 1758825748,
      "id": "kling-2.5-turbo-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [],
          "durations": [
            "5s",
            "10s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Kling 2.5 Turbo Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.39
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-distilled-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Longcat Distilled",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.09
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-distilled-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Longcat Distilled",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.09
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-image-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Longcat Full Quality",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.25
      }
    },
    {
      "created": 1764806400,
      "id": "longcat-text-to-video",
      "model_spec": {
        "privacy": "private",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "5s",
            "10s",
            "15s",
            "20s",
            "30s"
          ],
          "audio": false,
          "audio_configurable": false
        },
        "name": "Longcat Full Quality",
        "modelSource": "https://huggingface.co/meituan-longcat/LongCat-Video",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.25
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-fast-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Veo 3 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.44
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-fast-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [],
          "durations": [
            "8s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Veo 3 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.88
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-full-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Veo 3 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.88
      }
    },
    {
      "created": 1758825748,
      "id": "veo3-full-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9"
          ],
          "resolutions": [],
          "durations": [
            "8s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Veo 3 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.76
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-fast-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "Veo 3.1 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.66
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-fast-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "8s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "Veo 3.1 Fast",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.32
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-full-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "6s",
            "8s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "Veo 3.1 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 1.76
      }
    },
    {
      "created": 1729030447,
      "id": "veo3.1-full-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "8s"
          ],
          "audio": true,
          "audio_configurable": true
        },
        "name": "Veo 3.1 Full Quality",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 3.52
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Sora 2",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.44
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-pro-image-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "image-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Sora 2 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 2.22
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Sora 2",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 0.44
      }
    },
    {
      "created": 1758825748,
      "id": "sora-2-pro-text-to-video",
      "model_spec": {
        "privacy": "anonymized",
        "constraints": {
          "model_type": "text-to-video",
          "aspect_ratios": [
            "16:9",
            "9:16"
          ],
          "resolutions": [
            "720p",
            "1080p"
          ],
          "durations": [
            "4s",
            "8s",
            "12s"
          ],
          "audio": true,
          "audio_configurable": false
        },
        "name": "Sora 2 Pro",
        "offline": false,
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "video",
      "pricing": {
        "base_price_usd": 2.22
      }
    }
  ],
  "other": [
    {
      "created": 1741924661,
      "id": "text-embedding-bge-m3",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 0.15,
            "diem": 0.15
          },
          "output": {
            "usd": 0.6,
            "diem": 0.6
          }
        },
        "name": "BGE-M3",
        "modelSource": "https://huggingface.co/BAAI/bge-m3",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "embedding"
    },
    {
      "created": 1742418046,
      "id": "tts-kokoro",
      "model_spec": {
        "pricing": {
          "input": {
            "usd": 3.5,
            "diem": 3.5
          }
        },
        "voices": [
          "af_alloy",
          "af_aoede",
          "af_bella",
          "af_heart",
          "af_jadzia",
          "af_jessica",
          "af_kore",
          "af_nicole",
          "af_nova",
          "af_river",
          "af_sarah",
          "af_sky",
          "am_adam",
          "am_echo",
          "am_eric",
          "am_fenrir",
          "am_liam",
          "am_michael",
          "am_onyx",
          "am_puck",
          "am_santa",
          "bf_alice",
          "bf_emma",
          "bf_lily",
          "bm_daniel",
          "bm_fable",
          "bm_george",
          "bm_lewis",
          "ef_dora",
          "em_alex",
          "em_santa",
          "ff_siwis",
          "hf_alpha",
          "hf_beta",
          "hm_omega",
          "hm_psi",
          "if_sara",
          "im_nicola",
          "jf_alpha",
          "jf_gongitsune",
          "jf_nezumi",
          "jf_tebukuro",
          "jm_kumo",
          "pf_dora",
          "pm_alex",
          "pm_santa",
          "zf_xiaobei",
          "zf_xiaoni",
          "zf_xiaoxiao",
          "zf_xiaoyi",
          "zm_yunjian",
          "zm_yunxi",
          "zm_yunxia",
          "zm_yunyang"
        ],
        "name": "Kokoro Text to Speech",
        "modelSource": "https://huggingface.co/hexgrad/Kokoro-82M",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "tts"
    },
    {
      "created": 1744453050,
      "id": "upscaler",
      "model_spec": {
        "pricing": {
          "generation": {
            "usd": 0.01,
            "diem": 0.01
          },
          "upscale": {
            "2x": {
              "usd": 0.02,
              "diem": 0.02
            },
            "4x": {
              "usd": 0.08,
              "diem": 0.08
            }
          }
        },
        "name": "Upscaler",
        "offline": false,
        "privacy": "private",
        "traits": []
      },
      "object": "model",
      "owned_by": "venice.ai",
      "type": "upscale"
    }
  ]
};
    </script>

    <script>
        let currentTab = 'text';
        let sortKey = 'price_avg';
        let sortAsc = true;

        // Active filters state
        let activeFilters = new Set();

        const get = (obj, path, def = null) => {
            try {
                const val = path.split('.').reduce((acc, part) => acc[part], obj);
                return (val !== undefined && val !== null) ? val : def;
            } catch (e) {
                return def;
            }
        };


        // --- Configuration ---

        const filters = {
            text: [
                { id: 'supportsReasoning', label: 'üß† Reasoning' },
                { id: 'supportsVision', label: 'üëÅÔ∏è Vision' },
                { id: 'supportsFunctionCalling', label: 'üõ†Ô∏è Func Call' },
                { id: 'optimizedForCode', label: 'üíª Code' },
                { id: 'supportsWebSearch', label: 'üåê Web Search' },
                { id: 'supportsLogProbs', label: 'üìä Logprobs' },
                { id: 'supportsResponseSchema', label: 'üìã JSON Mode' },
                { id: 'hasCache', label: '‚ö° Caching' }
            ],
            image: [
                { id: 'hasUpscale', label: 'üîç Upscale' }
            ],
            video: [
                { id: 'text-to-video', label: 'üìù Text-to-Video' },
                { id: 'image-to-video', label: 'üñºÔ∏è Image-to-Video' },
                { id: '1080p', label: 'üì∫ 1080p' },
                { id: 'audio', label: 'üéµ Audio' }
            ]
        };

        const headers = {
            text: [
                { key: 'name', label: 'Model', class: 'col-model' },
                { key: 'price_combined', label: 'Pricing ($/1M) <div class="price-header-sort"><span id="sort_in">In</span> | <span id="sort_avg">Avg</span> | <span id="sort_out">Out</span></div>', class: 'col-combined-price' },
                { key: 'cache_price', label: 'Cache ($/1M)', class: 'col-price' },
                { key: 'context', label: 'Context', class: 'col-ctx' },
                { key: 'caps', label: 'Capabilities', class: 'col-caps' }
            ],
            image: [
                { key: 'name', label: 'Model', class: 'col-model' },
                { key: 'price_gen', label: 'Generation Price', class: 'col-price' },
                { key: 'steps', label: 'Steps', class: '' },
                { key: 'upscale', label: 'Upscale', class: '' }
            ],
            video: [
                { key: 'name', label: 'Model', class: 'col-model' },
                { key: 'price_video', label: 'Pricing', class: 'col-price' },
                { key: 'res', label: 'Resolutions', class: '' },
                { key: 'audio', label: 'Audio', class: '' }
            ]
        };

        const strategies = {
            text: {
                getPrice: (m) => (get(m, 'model_spec.pricing.input.usd', 0) + get(m, 'model_spec.pricing.output.usd', 0)) / 2,
                getCachePrice: (m) => get(m, 'model_spec.pricing.cache_input.usd', null),
                renderPrice: (m, max) => {
                    const input = get(m, 'model_spec.pricing.input.usd', 0);
                    const output = get(m, 'model_spec.pricing.output.usd', 0);
                    const avg = (input + output) / 2;
                    const pct = max > 0 ? (avg / max) * 100 : 0;


                    return `
                        <div class="price-bridge" title="Avg: $${avg.toFixed(3)}/1M tokens">
                            <div class="price-bridge-top">
                                <div class="price-value-group">
                                    <span class="price-value-num">$${input}</span>
                                    <span class="price-value-label">Input</span>
                                </div>
                                <div class="price-bridge-avg-info">
                                    Avg $${avg.toFixed(2)}
                                </div>
                                <div class="price-value-group" style="text-align: right;">
                                    <span class="price-value-num">$${output}</span>
                                    <span class="price-value-label">Output</span>
                                </div>
                            </div>
                            <div class="rel-bar-container">
                                <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                            </div>
                        </div>
                    `;
                },
                renderCachePrice: (m, maxCache) => {
                    const cache = get(m, 'model_spec.pricing.cache_input.usd');
                    if (cache === undefined || cache === null) return `<span style="color:var(--text-muted);opacity:0.5">‚Äî</span>`;

                    const pct = maxCache > 0 ? (cache / maxCache) * 100 : 0;
                    return `
                    <div class="price-cell">
                        <div class="price-val">$${cache}</div>
                        <div class="rel-bar-container" title="Relative Cache Cost: ${Math.round(pct)}%">
                            <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                        </div>
                    </div>
                `;
                },
                renderCaps: (m) => {
                    const c = get(m, 'model_spec.capabilities', {});
                    const pricing = get(m, 'model_spec.pricing', {});
                    const caps = [
                        { k: 'supportsReasoning', label: 'Reasoning', cls: 'feat-reasoning' },
                        { k: 'supportsVision', label: 'Vision', cls: 'feat-vision' },
                        { k: 'supportsFunctionCalling', label: 'Func Call', cls: 'feat-func' },
                        { k: 'optimizedForCode', label: 'Code', cls: 'feat-code' },
                        { k: 'supportsWebSearch', label: 'Web Search', cls: 'feat-search' },
                        { k: 'supportsLogProbs', label: 'Logprobs', cls: 'feat-logprobs' },
                        { k: 'supportsResponseSchema', label: 'JSON Mode', cls: 'feat-json' }
                    ];

                    let badges = caps
                        .filter(cap => c[cap.k] === true)
                        .map(cap => `<span class="feature-badge ${cap.cls}">${cap.label}</span>`);

                    if (pricing.cache_input) {
                        badges.push(`<span class="feature-badge feat-cache">Cache</span>`);
                    }

                    if (badges.length === 0) return '<span style="color:var(--text-muted);opacity:0.5">‚Äî</span>';
                    return `<div class="feature-tags">${badges.join('')}</div>`;
                },
                renderCtx: (m) => {
                    const t = get(m, 'model_spec.availableContextTokens', 0);
                    return Math.round(t / 1024) + 'k';
                },
                checkFilter: (m, fid) => {
                    if (fid === 'hasCache') return get(m, 'model_spec.pricing.cache_input.usd') !== null;
                    return get(m, 'model_spec.capabilities.' + fid) === true;
                }
            },
            image: {
                getPrice: (m) => get(m, 'model_spec.pricing.generation.usd', 0),
                renderPrice: (m, max) => {
                    const p = get(m, 'model_spec.pricing.generation.usd', 0);
                    const pct = max > 0 ? (p / max) * 100 : 0;
                    return `
                    <div class="price-cell">
                        <div class="price-val">$${p} / img</div>
                        <div class="rel-bar-container">
                            <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                        </div>
                    </div>
                `;
                },
                renderCaps: (m) => '',
                checkFilter: (m, fid) => {
                    if (fid === 'hasUpscale') return !!get(m, 'model_spec.pricing.upscale.2x.usd');
                    return false;
                }
            },
            video: {
                getPrice: (m) => get(m, 'pricing.base_price_usd', 0),
                renderPrice: (m, max) => {
                    const p = get(m, 'pricing.base_price_usd');
                    if (p === undefined) return `<span class="tag">Dynamic</span>`;

                    const pct = max > 0 ? (p / max) * 100 : 0;
                    return `
                    <div class="price-cell">
                        <div class="price-val">$${p.toFixed(2)}</div>
                        <div class="rel-bar-container">
                            <div class="rel-bar-bg"><div class="rel-bar-fill ${getBarColor(pct)}" style="width:${pct}%"></div></div>
                        </div>
                    </div>
                `;
                },
                renderCaps: (m) => '',
                checkFilter: (m, fid) => {
                    if (fid === 'audio') return get(m, 'model_spec.constraints.audio', false);
                    if (fid === 'text-to-video') return get(m, 'model_spec.constraints.model_type') === 'text-to-video';
                    if (fid === 'image-to-video') return get(m, 'model_spec.constraints.model_type') === 'image-to-video';
                    if (fid === '1080p') return (get(m, 'model_spec.constraints.resolutions') || []).includes('1080p');
                    return false;
                }
            }
        };

        function getBarColor(p) {
            if (p < 33) return 'bar-low';
            if (p < 66) return 'bar-med';
            return 'bar-high';
        }

        // --- Main Logic ---

        function switchTab(t) {
            currentTab = t;
            activeFilters.clear(); // Clear filters when switching tabs

            // Reset sort defaults
            if (t === 'text') sortKey = 'price_avg';
            else if (t === 'image') sortKey = 'price_gen';
            else if (t === 'video') sortKey = 'price_video';

            sortAsc = true;

            document.querySelectorAll('.tab-btn').forEach(b => b.classList.toggle('active', b.textContent.toLowerCase() === t));

            renderFilters();
            renderTable();
        }

        function toggleFilter(fid) {
            if (activeFilters.has(fid)) {
                activeFilters.delete(fid);
            } else {
                activeFilters.add(fid);
            }
            renderTable();
        }

        function renderFilters() {
            const bar = document.getElementById('filterBar');
            const available = filters[currentTab] || [];

            if (available.length === 0) {
                bar.style.display = 'none';
                bar.innerHTML = '';
                return;
            }

            bar.style.display = 'flex';
            bar.innerHTML = available.map(f => `
            <label class="filter-item">
                <input type="checkbox" onchange="toggleFilter('${f.id}')" ${activeFilters.has(f.id) ? 'checked' : ''}>
                <span>${f.label}</span>
            </label>
        `).join('');
        }

        function handleSort(key) {
            // Price rotation for Text Tab
            if (key === 'price_combined' && currentTab === 'text') {
                if (sortKey === 'price_avg') sortKey = 'price_input';
                else if (sortKey === 'price_input') sortKey = 'price_output';
                else sortKey = 'price_avg';
                sortAsc = true;
            }
            // Fallback for Generic price sorting (Image/Video)
            else if (key === 'price_gen' || key === 'price_video' || key === 'price_combined') {
                sortKey = 'price_avg';
                sortAsc = !sortAsc;
            }
            else {
                if (sortKey === key) sortAsc = !sortAsc;
                else {
                    sortKey = key;
                    sortAsc = true;
                }
            }
            renderTable();
        }

        function renderTable() {
            const thead = document.getElementById('tableHead');
            const tbody = document.getElementById('tableBody');
            const cols = headers[currentTab];
            const models = window.veniceModels[currentTab] || [];
            const term = document.getElementById('searchInput').value.toLowerCase();

            // 1. Render Headers
            thead.innerHTML = `<tr>
            ${cols.map(c => {
                let label = c.label;
                const isPriceCombined = c.key === 'price_combined';
                if (isPriceCombined) {
                    const activeIn = sortKey === 'price_input' ? 'active-sort' : '';
                    const activeAvg = sortKey === 'price_avg' ? 'active-sort' : '';
                    const activeOut = sortKey === 'price_output' ? 'active-sort' : '';
                    label = `Pricing ($/1M) <div class="price-header-sort">
                        <span class="${activeIn}" onclick="event.stopPropagation(); handleSort('price_input')">In</span> | 
                        <span class="${activeAvg}" onclick="event.stopPropagation(); handleSort('price_avg')">Avg</span> | 
                        <span class="${activeOut}" onclick="event.stopPropagation(); handleSort('price_output')">Out</span>
                    </div>`;
                }
                const isActive = sortKey === c.key || (isPriceCombined && sortKey.startsWith('price_'));
                const icon = isActive ? (sortAsc ? '‚ñ≤' : '‚ñº') : '';
                return `<th class="${c.class}" onclick="handleSort('${c.key}')">${label} ${icon}</th>`;
            }).join('')}
        </tr>`;

            // 2. Filter
            let data = models.filter(m => {
                // Text Search
                const n = get(m, 'model_spec.name', '').toLowerCase();
                const i = m.id.toLowerCase();
                const s = get(m, 'model_spec.modelSource', '').toLowerCase();
                if (!(n.includes(term) || i.includes(term) || s.includes(term))) return false;

                // Capability Filters
                const strat = strategies[currentTab];
                for (let fid of activeFilters) {
                    if (!strat.checkFilter(m, fid)) return false;
                }

                return true;
            });

            // 3. Prepare Sort Data & Max Price
            const currentStrat = strategies[currentTab];
            const maxPrice = Math.max(0, ...data.map(m => currentStrat.getPrice(m)));
            const maxCache = (currentTab === 'text') ? Math.max(0.00001, ...data.map(m => currentStrat.getCachePrice(m) || 0)) : 0;

            data.forEach(m => {
                if (currentTab === 'text') {
                    m._sort_price_input = get(m, 'model_spec.pricing.input.usd', 0);
                    m._sort_price_output = get(m, 'model_spec.pricing.output.usd', 0);
                    m._sort_price_avg = (m._sort_price_input + m._sort_price_output) / 2;
                } else if (currentTab === 'image') {
                    m._sort_price_avg = get(m, 'model_spec.pricing.generation.usd', 0);
                } else if (currentTab === 'video') {
                    m._sort_price_avg = get(m, 'pricing.base_price_usd', 0);
                }
                m._sort_cache = (currentTab === 'text') ? (currentStrat.getCachePrice(m) || 0) : 0;
                m._sort_name = get(m, 'model_spec.name', '');
                m._sort_context = get(m, 'model_spec.availableContextTokens', 0);
            });

            // 4. Sort
            data.sort((a, b) => {
                let valA, valB;
                if (sortKey === 'price_input') { valA = a._sort_price_input; valB = b._sort_price_input; }
                else if (sortKey === 'price_output') { valA = a._sort_price_output; valB = b._sort_price_output; }
                else if (sortKey === 'price_avg') { valA = a._sort_price_avg; valB = b._sort_price_avg; }
                else if (sortKey === 'cache_price') { valA = a._sort_cache; valB = b._sort_cache; }
                else if (sortKey === 'name') { valA = a._sort_name; valB = b._sort_name; }
                else if (sortKey === 'created') { valA = a._sort_created; valB = b._sort_created; }
                else if (sortKey === 'context') { valA = a._sort_context; valB = b._sort_context; }
                else { valA = a._sort_price_avg; valB = b._sort_price_avg; }

                if (valA < valB) return sortAsc ? -1 : 1;
                if (valA > valB) return sortAsc ? 1 : -1;
                return 0;
            });

            // 5. Render Rows
            tbody.innerHTML = data.map(m => {
                const spec = m.model_spec || {};

                // Common Cells
                const q = get(m, 'model_spec.capabilities.quantization');
                const nameCell = `
                    <div>
                        <a href="${spec.modelSource || '#'}" target="_blank" class="model-name">${spec.name || m.id}</a>
                        <div class="model-id">${m.id} ${q ? `<span class="cap-badge" style="opacity:1; background:var(--bar-bg); border:none;">${q}</span>` : ''}</div> 
                        <div class="tag-row">${(spec.traits || []).map(t => `<span class="cap-badge">${t}</span>`).join('')}</div>
                    </div>
                `;

                // Specific Cells
                if (currentTab === 'text') {
                    return `
                        <tr>
                            <td>${nameCell}</td>
                            <td>${currentStrat.renderPrice(m, maxPrice)}</td>
                            <td>${currentStrat.renderCachePrice(m, maxCache)}</td>
                            <td>${currentStrat.renderCtx(m)}</td>
                            <td>${currentStrat.renderCaps(m)}</td>
                        </tr>
                    `;
                } else if (currentTab === 'image') {
                    const steps = get(m, 'model_spec.constraints.steps.max', 'N/A');
                    const upscale = get(m, 'model_spec.pricing.upscale.2x.usd') ? `$${get(m, 'model_spec.pricing.upscale.2x.usd')} (2x)` : '‚Äî';
                    return `
                        <tr>
                            <td>${nameCell}</td>
                            <td>${currentStrat.renderPrice(m, maxPrice)}</td>
                            <td>${steps}</td>
                            <td>${upscale}</td>
                        </tr>
                    `;
                } else if (currentTab === 'video') {
                    const res = (get(m, 'model_spec.constraints.resolutions') || []).join(', ');
                    const audio = get(m, 'model_spec.constraints.audio') ? '‚úÖ Yes' : '‚ùå No';
                    return `
                        <tr>
                            <td>${nameCell}</td>
                            <td>${currentStrat.renderPrice(m, maxPrice)}</td>
                            <td>${res}</td>
                            <td>${audio}</td>
                        </tr>
                    `;
                }
                return '';
            }).join('');
        }

        // Initialize
        renderFilters();
        renderTable();

    </script>
</body>

</html>